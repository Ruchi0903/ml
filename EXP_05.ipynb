{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc56c0c-fd76-4837-a07a-a2c12edad030",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -qq install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d6fe6f-cfc8-48be-8d24-826ed38a0a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from catboost import CatBoostClassifier, Pool, metrics, cv\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d967161c-696c-4c1e-b116-0ba7a063aa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw loan stats dataset\n",
    "data = pd.read_csv(\"LoanStats3a.csv\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c91fcc-395c-4454-a7a4-b2f30f69e54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the top 5 rows of data\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bd2b29-7a7b-4244-b474-4a0d6bc04f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of the dataset\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4845b2bb-3841-432b-9ae6-5083ddc3aa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking info of the raw dataframe\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b023594b-3726-4281-b08f-88cc6fcad46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab9c72a-ac0d-4637-98fb-ef8308147eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total percentage of null values in the data\n",
    "pct = (data.isnull().sum().sum())/(data.shape[0]*data.shape[1])\n",
    "print(\"Overall missing values in the data â‰ˆ {:.2f} %\".format(pct*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa39e287-e913-485e-b204-0878f59f5815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for null values using a heatmap as a visualizing tool\n",
    "plt.figure(figsize=(16,14))\n",
    "sns.heatmap(data.isnull())\n",
    "plt.title('Null values heat plot', fontdict={'fontsize': 20})\n",
    "plt.legend(data.isnull())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8e1d6c-860e-4404-8051-9ed09b53a4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe to display percentage of null values in different number of columns\n",
    "temp_df = pd.DataFrame()\n",
    "temp_df['Percentage of null values'] = ['10% or less', '10% to 20%', '20% to 30%', '30% to 40%', '40% to 50%',\n",
    "                                        '50% to 60%', '60% to 70%', '70% to 80%', '80% to 90%', 'More than 90%']\n",
    "\n",
    "# Store the columns count separately for each range\n",
    "ten_percent = len(data.columns[((data.isnull().sum())/len(data)) <= 0.1])\n",
    "# Calculate null percentage for all columns first\n",
    "null_percentage = (data.isnull().sum())/len(data)\n",
    "ten_to_twenty_percent = len(data.columns[(null_percentage <= 0.2) & (null_percentage > 0.1)]) # Use boolean indexing with the null_percentage series\n",
    "twenty_to_thirty_percent = len(data.columns[(null_percentage <= 0.3) & (null_percentage > 0.2)])\n",
    "thirty_to_forty_percent = len(data.columns[(null_percentage <= 0.4) & (null_percentage > 0.3)])\n",
    "forty_to_fifty_percent = len(data.columns[(null_percentage <= 0.5) & (null_percentage > 0.4)])\n",
    "fifty_to_sixty_percent = len(data.columns[(null_percentage <= 0.6) & (null_percentage > 0.5)])\n",
    "sixty_to_seventy_percent = len(data.columns[(null_percentage <= 0.7) & (null_percentage > 0.6)])\n",
    "seventy_to_eighty_percent = len(data.columns[(null_percentage <= 0.8) & (null_percentage > 0.7)])\n",
    "eighty_to_ninety_percent = len(data.columns[(null_percentage <= 0.9) & (null_percentage > 0.8)])\n",
    "hundred_percent = len(data.columns[(null_percentage > 0.9)])\n",
    "\n",
    "temp_df['No. of columns'] = [ten_percent, ten_to_twenty_percent, twenty_to_thirty_percent, thirty_to_forty_percent, forty_to_fifty_percent,\n",
    "                             fifty_to_sixty_percent, sixty_to_seventy_percent, seventy_to_eighty_percent, eighty_to_ninety_percent, hundred_percent]\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ded8e2-f99d-4347-a1b8-bd87bf3e2b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considering only those columns which have null values less than 40% in that particular column\n",
    "df1 = data[data.columns[((data.isnull().sum())/len(data)) < 0.4]]\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ac0b00-8bc1-4ec5-be96-be4a650f466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking columns that have only single values in them i.e, constant columns\n",
    "const_cols = []\n",
    "for i in df1.columns:\n",
    "    if df1[i].nunique() == 1:\n",
    "        const_cols.append(i)\n",
    "\n",
    "print(const_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ac5768-9a52-4c3f-95d7-1330fa9bc3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After observing the above output, we are dropping columns which have single values in them\n",
    "print(\"Shape before:\", df1.shape)\n",
    "df1.drop(const_cols, axis=1, inplace = True)\n",
    "print(\"Shape after:\", df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cb4151-f28b-4fbd-827a-c433105e8ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns other than numerical value\n",
    "colms = df1.columns[df1.dtypes == 'object']\n",
    "colms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60a1464-ddcc-485c-af92-36d4904efb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which columns needs to be converted to datetime\n",
    "df1[colms].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e774cd33-7f6a-4168-9da0-bfc5757e93a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting objects to datetime columns\n",
    "dt_cols = ['issue_d', 'earliest_cr_line', 'last_pymnt_d', 'last_credit_pull_d']\n",
    "for i in dt_cols:\n",
    "    df1[i] = pd.to_datetime(df1[i].astype('str'), format='%b-%y', yearfirst=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44b5649-fc92-401e-b042-272fd4bc7cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the new datetime columns\n",
    "df1[['issue_d','earliest_cr_line','last_pymnt_d','last_credit_pull_d']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9b4a1c-d675-488d-9550-7f49b3b954d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considering only year of joining for 'earliest_cr_line' column\n",
    "df1['earliest_cr_line'] = pd.DatetimeIndex(df1['earliest_cr_line']).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac00c97-97d8-46d1-9388-12b06d2d6e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding new features by getting month and year from [issue_d, last_pymnt_d, and last_credit_pull_d] columns\n",
    "df1['issue_d_year'] = pd.DatetimeIndex(df1['issue_d']).year\n",
    "df1['issue_d_month'] = pd.DatetimeIndex(df1['issue_d']).month\n",
    "df1['last_pymnt_d_year'] = pd.DatetimeIndex(df1['last_pymnt_d']).year\n",
    "df1['last_pymnt_d_month'] = pd.DatetimeIndex(df1['last_pymnt_d']).month\n",
    "df1['last_credit_pull_d_year'] = pd.DatetimeIndex(df1['last_credit_pull_d']).year\n",
    "df1['last_credit_pull_d_month'] = pd.DatetimeIndex(df1['last_credit_pull_d']).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2010a202-b829-474a-b42a-0bc739e12c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction\n",
    "df1.earliest_cr_line = 2019 - (df1.earliest_cr_line)\n",
    "df1.issue_d_year = 2019 - (df1.issue_d_year)\n",
    "df1.last_pymnt_d_year = 2019 - (df1.last_pymnt_d_year)\n",
    "df1.last_credit_pull_d_year = 2019 - (df1.last_credit_pull_d_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff7da64-7642-4d81-9d1a-7d90f916e30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the original features to avoid data redundancy\n",
    "df1.drop(['issue_d','last_pymnt_d','last_credit_pull_d'], axis=1, inplace=True)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178750bf-7273-4ca5-a44b-7b8a069d2a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for null values in the updated dataframe\n",
    "plt.figure(figsize=(16,10))\n",
    "sns.heatmap(df1.isnull())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0846fd-2c6e-479f-afc5-0fe9442375fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for Percentage of null values\n",
    "a = (df1.isnull().sum() / df1.shape[0]) * 100\n",
    "b = a[a > 0.00]\n",
    "b = pd.DataFrame(b, columns = ['Percentage of null values'])\n",
    "b.sort_values(by= ['Percentage of null values'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41849aa5-6182-43f7-9092-56bea714ad10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the 29 rows which have null values in few columns\n",
    "df1 = df1[df1['delinq_2yrs'].notnull()]\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b99b909-8f11-440d-96f4-47efdf129955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking again for Percentage of null values\n",
    "a = (df1.isnull().sum() / df1.shape[0]) * 100\n",
    "b = a[a > 0.00]\n",
    "b = pd.DataFrame(b, columns = ['Percentage of null values'])\n",
    "b.sort_values(by= ['Percentage of null values'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a35d3be-da71-45bb-98ca-f960b7ae43f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing the null values with the median value\n",
    "# Check if the column exists before imputing\n",
    "if 'last_pymnt_d_year' in df1.columns:\n",
    "    df1['last_pymnt_d_year'].fillna(df1['last_pymnt_d_year'].median(), inplace=True)\n",
    "if 'last_pymnt_d_month' in df1.columns:\n",
    "    df1['last_pymnt_d_month'].fillna(df1['last_pymnt_d_month'].median(), inplace=True)\n",
    "if 'last_credit_pull_d_year' in df1.columns:\n",
    "    df1['last_credit_pull_d_year'].fillna(df1['last_credit_pull_d_year'].median(), inplace=True)\n",
    "if 'last_credit_pull_d_month' in df1.columns:\n",
    "    df1['last_credit_pull_d_month'].fillna(df1['last_credit_pull_d_month'].median(), inplace=True)\n",
    "if 'tax_liens' in df1.columns:\n",
    "    df1['tax_liens'].fillna(df1['tax_liens'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0c2ee6-cce2-4fdc-88c5-18b52cef94df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 'revol_util' column, fill null values with 50%\n",
    "df1.revol_util.fillna('50%', inplace=True)\n",
    "\n",
    "# Extracting numerical value from string\n",
    "df1.revol_util = df1.revol_util.apply(lambda x: x[:-1])\n",
    "\n",
    "# Converting string to float\n",
    "df1.revol_util = df1.revol_util.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4339a5-aac5-4d02-b460-95bf469a4ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values in 'pub_rec_bankruptcies' column\n",
    "df1.pub_rec_bankruptcies.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5267cf01-f5b5-47fe-9517-07cb93972cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill 'pub_rec_bankruptcies' column\n",
    "df1['pub_rec_bankruptcies'].fillna(df1['pub_rec_bankruptcies'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3d915e-4828-47c1-a47e-7d3f78c29fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values in 'emp_length' column\n",
    "df1['emp_length'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8cc894-1c25-403e-b7fa-820b20af127b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating null values by assigning a random string\n",
    "df1['emp_length'].fillna('5000',inplace=True)\n",
    "\n",
    "# Filling '< 1 year' as '0 years' of experience and '10+ years' as '10 years'\n",
    "df1.emp_length.replace({'10+ years':'10 years', '< 1 year':'0 years'}, inplace=True)\n",
    "\n",
    "# Then extract numerical value from the string\n",
    "df1.emp_length = df1.emp_length.apply(lambda x: x[:2])\n",
    "\n",
    "# Converting it's dattype to float\n",
    "df1.emp_length = df1.emp_length.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bb1a7d-7108-4498-b770-b2bae59181d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking again for Percentage of null values\n",
    "a = (df1.isnull().sum() / df1.shape[0]) * 100\n",
    "b = a[a > 0.00]\n",
    "b = pd.DataFrame(b, columns = ['Percentage of null values'])\n",
    "b.sort_values(by= ['Percentage of null values'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbdccaa-9e0e-4c8a-9e1d-6319d99d336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing redundant features and features which have percentage null values > 5%\n",
    "# Check if columns exist before dropping\n",
    "columns_to_drop = ['desc', 'emp_title', 'title']\n",
    "existing_columns = df1.columns\n",
    "columns_to_drop = [col for col in columns_to_drop if col in existing_columns]\n",
    "\n",
    "# Drop only existing columns\n",
    "if columns_to_drop:\n",
    "    df1.drop(columns_to_drop, axis=1, inplace=True)\n",
    "\n",
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bc503f-9d27-4099-a8d6-4f098be99bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8b3b6a-352f-4086-8f2d-761143f6e89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values in 'term' column\n",
    "df1['term'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c053507b-66d4-44d0-ad1d-99e1e1af98e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values in 'int_rate' column\n",
    "df1['int_rate'].unique()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755fb273-bf29-4bc6-9f0c-65adbe354e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting 'term' and 'int_rate' to numerical columns\n",
    "df1.term = df1.term.apply(lambda x: x[1:3])\n",
    "df1.term = df1.term.astype('float')\n",
    "df1.int_rate = df1.int_rate.apply(lambda x: x[:2])\n",
    "df1.int_rate = df1.int_rate.astype('float')\n",
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d25fe8-22b0-45b6-9d31-836bb8c79240",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.drop('zip_code', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84be41e-4eaa-44ff-bece-3f2176829267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding on categorical columns\n",
    "df2 = pd.get_dummies(df2, columns = ['home_ownership', 'verification_status', 'purpose', 'addr_state', 'debt_settlement_flag'], drop_first = True)\n",
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47b5b68-e933-4050-991e-8eb6d07a4681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding on 'grade' column\n",
    "le = LabelEncoder()\n",
    "le.fit(df2.grade)\n",
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759151a3-5a91-4940-b277-2e3cc5b36bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.grade = le.transform(df2.grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199c6340-15d2-4b6f-9da6-5255f145ab5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding on 'sub_grade' column\n",
    "le2 = LabelEncoder()\n",
    "le2.fit(df2.sub_grade)\n",
    "le2.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8eeeb66-ce40-42cd-9623-08041a4d896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update 'sub_grade' column\n",
    "df2.sub_grade = le2.transform(df2.sub_grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48fc366-27ba-466a-800d-76cadc8357ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c63f54-f0bb-4ef1-8aae-9406e634e9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target feature\n",
    "df2['loan_status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572091b9-2d13-422c-bc9b-40d261bce162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction features\n",
    "X = df2.drop(\"loan_status\", axis = 1)\n",
    "# Target variable\n",
    "y = df2['loan_status']\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07af522-2209-41b5-85e4-0de6d88b1613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding the target variable\n",
    "le3 = LabelEncoder()\n",
    "le3.fit(y)\n",
    "y_transformed = le3.transform(y)\n",
    "y_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34626221-156e-431e-8af0-68bf11227c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39eeff3a-9ae6-47ca-9341-9b247c7a9057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y_transformed, test_size = 0.20, stratify = y_transformed, random_state = 2)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f062b5d2-8fb5-431c-a578-ccf861dd4a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using DecisionTree as base model\n",
    "giniDecisionTree = DecisionTreeClassifier(criterion='gini', random_state = 100,\n",
    "                                          max_depth=3, class_weight = 'balanced', min_samples_leaf = 5)\n",
    "giniDecisionTree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6bd560-cdeb-4d68-8791-63fee7dbd276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediciton using DecisionTree\n",
    "giniPred = giniDecisionTree.predict(x_test)\n",
    "print('Accuracy Score: ', accuracy_score(y_test, giniPred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1ceaec-2b46-4123-861f-cf2e9c97fe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CatBoostClassifier object\n",
    "CatBoost_clf = CatBoostClassifier(iterations=5,\n",
    "                                  learning_rate=0.1,\n",
    "                                  #loss_function='CrossEntropy'\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1befcd7-5849-4fa2-8e36-23309f9cd4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_features = list(range(0, X.shape[1]))\n",
    "CatBoost_clf.fit(x_train, y_train,\n",
    "                 #cat_features=cat_features,\n",
    "                 eval_set = (x_test, y_test),\n",
    "                 verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4979b1c9-37cc-4a0c-855e-a9208c797847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction using CatBoost\n",
    "cbr_prediction = CatBoost_clf.predict(x_test)\n",
    "print('Accuracy Score: ', accuracy_score(y_test, cbr_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c51e76c-6077-4d1f-8382-68dd0c377e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Classification report for CatBoost model\n",
    "print('Classification Report for CatBoost:')\n",
    "print(classification_report(y_test, cbr_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a65b19b-b4f2-488f-bb7a-752952722872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create XGBClassifier object\n",
    "XGB_clf = XGBClassifier(learning_rate = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091a8cba-617c-40ae-94dc-446917d92c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit on training set\n",
    "XGB_clf.fit(x_train, y_train,\n",
    "            eval_set = [(x_train, y_train), (x_test, y_test)],\n",
    "            verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a30df4-75d5-41e9-8cad-84e0ab7c97ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction using XGBClassifier\n",
    "XGB_prediction = XGB_clf.predict(x_test)\n",
    "print('Accuracy Score: ', accuracy_score(y_test, XGB_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e851875-7202-4041-b16a-e5307a269099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report for XGBoost\n",
    "\n",
    "print('Classification Report for XGBoost:')\n",
    "print(classification_report(y_test, XGB_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdc9a52-9b22-45e1-a757-dfb56fe19825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LGBMClassifier object\n",
    "LGBM_clf = LGBMClassifier(learning_rate = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fc8f64-5f68-4b3e-a81d-78cb3d8bf995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit on training set\n",
    "LGBM_clf.fit(x_train, y_train,\n",
    "             eval_set = [(x_train, y_train), (x_test, y_test)],\n",
    "             # Instead of verbose = False, remove it or replace with callbacks=[lightgbm.callback.early_stopping(stopping_rounds, verbose=False)]\n",
    "             # in this case we are just removing it\n",
    "             #callbacks=[lightgbm.callback.early_stopping(10, verbose=False)]\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9bda94-44d9-4034-9ae6-00a7b3f0e4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction using LGBMClassifier\n",
    "LGBM_prediction = LGBM_clf.predict(x_test)\n",
    "print('Accuracy Score: ', accuracy_score(y_test, LGBM_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e754237e-d034-4d08-a903-0b4555cde82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report for LGBM\n",
    "\n",
    "print('Classification Report for LGBM:')\n",
    "print(classification_report(y_test, LGBM_prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
